{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG8c28jfqUY6"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuzImWedqUY9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from functools import reduce\n",
        "\n",
        "USE_DRIVE = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk_GLc_VqUZB"
      },
      "outputs": [],
      "source": [
        "# check if Colab is used to mount the drive\n",
        "USING_COLAB = False\n",
        "if USE_DRIVE:\n",
        "\ttry:\n",
        "\t\tfrom google.colab import drive\n",
        "\t\t# store logs on google drive to avoid colab crash\n",
        "\t\tdrive.mount('/content/drive')\n",
        "\t\tUSING_COLAB = True\n",
        "\texcept:\n",
        "\t\tUSING_COLAB = False\n",
        "\t\tpass\n",
        "\n",
        "# download the images\n",
        "if not (os.path.isfile(\"annotations_train.csv\") and os.path.isdir(\"test\") and os.path.isdir(\"train\")):\n",
        "\t# !wget -c 'https://github.com/itLovaz/DL_Project/raw/main/dataset.zip'\n",
        "\t!gdown --id 14upp5aMYjBwDR57u_H4hMfMKYx5zw8k6\n",
        "\t!unzip dataset.zip > /dev/null\n",
        "\t!rm -r dataset.zip\n",
        "\n",
        "# Download our pretrained classification model\n",
        "if not os.path.isdir(\"pretrained_models\"):\n",
        "\t!gdown --id 116ScZ5oGOQVKDFWLC6DI-4q61-FIw8l4\n",
        "\t!mkdir pretrained_models\n",
        "\t!mv resnet_18_acc_70_30_seed_26_88.63.h5 pretrained_models/resnet_18_acc_70_30_seed_26_88.63.h5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3jOAzKGqUZE"
      },
      "source": [
        "# Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pY8UtHJQqUZF"
      },
      "outputs": [],
      "source": [
        "# group file images by id and create a dict\n",
        "def group_files_per_id(file_list):\n",
        "\tfile_list_per_id = {}\n",
        "\tfor file in file_list:\n",
        "\t\timg_id = int(file.split(\"_\")[0])\n",
        "\t\tif file_list_per_id.get(img_id) is None:\n",
        "\t\t\tfile_list_per_id[img_id] = [file]\n",
        "\t\telse:\n",
        "\t\t\tfile_list_per_id[img_id].append(file)\n",
        "\treturn file_list_per_id"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FpaKJ8OqUZG"
      },
      "source": [
        "## Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tcyZ_aAqUZH"
      },
      "outputs": [],
      "source": [
        "class ReidTrainDataset(Dataset):\n",
        "\tdef __init__(self, file_list, directory, min_group_length = 12, n_select = 12) -> None:\n",
        "\t\tsuper().__init__()\n",
        "\t\tassert min_group_length >= n_select\n",
        "\t\tself.dir = directory\n",
        "\t\tself.n_select = n_select\n",
        "\n",
        "\t\tself.transform = T.Compose([\n",
        "\t\t\tT.ToTensor(),\n",
        "\t\t\tT.Normalize(mean=[0.], std=[1.])\n",
        "\t\t])\n",
        "\n",
        "\t\tself.augmentation = T.Compose([\n",
        "\t\t\tT.RandomRotation(degrees=(0,15)),\n",
        "\t\t\tT.RandomCrop((96, 48)),\n",
        "\t\t\tT.Resize((128, 64)),\n",
        "\t\t\tT.RandomHorizontalFlip(p=0.5),\n",
        "\t\t])\n",
        "\n",
        "\t\t# group images by id\n",
        "\t\tfile_list_per_id = group_files_per_id(file_list)\n",
        "\n",
        "\t\t# add augmentation to images to reach the minimmum number of images per id\n",
        "\t\tfor k, v in file_list_per_id.items():\n",
        "\t\t\tnon_augm_list = v.copy()\n",
        "\t\t\tfor i in range(min_group_length - len(v)):\n",
        "\t\t\t\tfile_list_per_id[k].append(\"#\" + np.random.choice(non_augm_list))\n",
        "\n",
        "\t\tself.file_batches = list(file_list_per_id.values())\n",
        "\t\n",
        "\tdef __getitem__(self, index): # get directly a minibatch of images with the same id\n",
        "\t\tminibatch = torch.Tensor()\n",
        "\t\tfiles = np.array(self.file_batches[index])\n",
        "\t\tnp.random.shuffle(files)\n",
        "\t\tfor file in files[:self.n_select]:\n",
        "\t\t\taugment = file[0] == \"#\"\n",
        "\t\t\timg = Image.open(os.path.join(self.dir, file[1:] if augment else file))\n",
        "\t\t\tif augment:\n",
        "\t\t\t\timg = self.augmentation(img)\n",
        "\t\t\timg = self.transform(img)\n",
        "\t\t\timg = img[None, :]\n",
        "\t\t\tminibatch = torch.cat((minibatch, img))\n",
        "\n",
        "\t\treturn minibatch\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.file_batches)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01IZ1P_VqUZJ"
      },
      "source": [
        "## Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgUnijSYqUZK"
      },
      "outputs": [],
      "source": [
        "class ReidValidDataset(Dataset):\n",
        "\tdef __init__(self, file_list, directory) -> None:\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.dir = directory\n",
        "\t\tself.file_list = file_list\n",
        "\t\tself.transform = T.Compose([\n",
        "\t\t\tT.ToTensor(),\n",
        "\t\t\tT.Normalize(mean=[0.], std=[1.])\n",
        "\t\t])\n",
        "\n",
        "\t\t# group indexes of the images by id\n",
        "\t\tfile_list_per_id = {}\n",
        "\t\tfor i, file in enumerate(file_list):\n",
        "\t\t\timg_id = int(file.split(\"_\")[0])\n",
        "\t\t\tif file_list_per_id.get(img_id) is None:\n",
        "\t\t\t\tfile_list_per_id[img_id] = [i]\n",
        "\t\t\telse:\n",
        "\t\t\t\tfile_list_per_id[img_id].append(i)\n",
        "\n",
        "\t\t# compute ground truth\n",
        "\t\tself.ground_truth = {v[0]:set(v[1:]) for k,v in file_list_per_id.items()}\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\timg = Image.open(os.path.join(self.dir, self.file_list[index]))\n",
        "\t\tif self.transform:\n",
        "\t\t\timg = self.transform(img)\n",
        "\n",
        "\t\treturn img\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.file_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtmxyGElqUZM"
      },
      "outputs": [],
      "source": [
        "def get_data(train_batch_size, valid_batch_size, data_dir, train_samples_ratio = 0.7, min_group_length = 10, n_select = 10, seed = 26):\n",
        "\t# create training and validation sets\n",
        "\tfile_list = sorted(os.listdir(data_dir))\n",
        " \n",
        "\ttrain_list = []\n",
        "\tvalid_list = []\n",
        "\n",
        "\t# group images by id\n",
        "\tfile_list_per_id = group_files_per_id(file_list)\n",
        "\n",
        "\t# shuffle ids\n",
        "\tshuffled = np.array(list(file_list_per_id.keys()))\n",
        "\tnp.random.seed(seed)\n",
        "\tnp.random.shuffle(shuffled)\n",
        "\n",
        "\t# divide per id and create 2 list of images\n",
        "\tfor index, id in enumerate(shuffled):\n",
        "\t\tif index < train_samples_ratio * len(file_list_per_id):\n",
        "\t\t\ttrain_list.append(file_list_per_id[id])\n",
        "\t\telse:\n",
        "\t\t\tvalid_list.append(file_list_per_id[id])\n",
        "\t\n",
        "\t# unsqeeze\n",
        "\ttrain_list = np.array(reduce(lambda a, b: a+b, train_list))\n",
        "\tvalid_list = np.array(reduce(lambda a, b: a+b, valid_list))\n",
        "\n",
        "\ttraining_data = ReidTrainDataset(train_list, data_dir, min_group_length, n_select)\n",
        "\tvalidation_data = ReidValidDataset(valid_list, data_dir)\n",
        "\n",
        "\ttrain_loader = torch.utils.data.DataLoader(training_data, train_batch_size, shuffle=True)\n",
        "\tvalid_loader = torch.utils.data.DataLoader(validation_data, valid_batch_size, shuffle=False)\n",
        "\n",
        "\treturn train_loader, valid_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MwDcjxIqUZN"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvoipadMqUZP"
      },
      "source": [
        "## classification model (to load)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xew2qLWiqUZP"
      },
      "outputs": [],
      "source": [
        "class MyModel(nn.Module):\n",
        "\t\n",
        "\tlabels = [\n",
        "\t\t\"age\", \"backpack\", \"bag\", \"handbag\", \"down\", \"clothes\", \"up\", \"hair\", \"hat\", \n",
        "\t\t\"gender\", \"upblack\", \"upwhite\", \"upred\", \"uppurple\", \"upyellow\", \"upgray\", \n",
        "\t\t\"upblue\", \"upgreen\", \"downblack\", \"downwhite\", \"downpink\", \"downpurple\", \n",
        "\t\t\"downyellow\", \"downgray\", \"downblue\", \"downgreen\", \"downbrown\", \"upmulti\", \"downmulti\"]\n",
        "\n",
        "\tdef __init__(self, configuration):\n",
        "\t\tsuper().__init__()\n",
        "\t\n",
        "\t\tself.configuration = configuration\n",
        "\t\tself.model = self.configuration['model'] \n",
        "\t\tself.model.fc = nn.Identity() # bypass final layer\n",
        "\t\t\n",
        "\t\t# use an extra layer if original network last layer output size is too big\n",
        "\t\tif self.configuration['use_extra_fc_layer']:\n",
        "\t\t\tself.extra_layer = self.configuration['extra_layer']\n",
        "\n",
        "\t\t# apply last layer differently if age or other attributes\n",
        "\t\tself.relu = nn.ReLU()\n",
        "\t\tself.labelsFC = { label: None for label in self.labels }\n",
        "\t\tself.outputs = self.labelsFC.copy()\n",
        "\t\tfor label in self.labelsFC:\n",
        "\t\t\tif label == \"age\":\n",
        "\t\t\t\tself.labelsFC[label] = nn.Sequential(nn.Linear(self.configuration['last_layer_output_size'], 4), nn.Softmax(dim=1))\n",
        "\t\t\telse:\n",
        "\t\t\t\tself.labelsFC[label] = nn.Sequential(nn.Linear(self.configuration['last_layer_output_size'], 1), nn.Sigmoid())\n",
        "\n",
        "\t# ovverride to manage last layer\n",
        "\tdef to(self, *args, **kwargs):\n",
        "\t\tif args[0] == \"cuda\":\n",
        "\t\t\tself.model.cuda(*args)\n",
        "\t\telse:\n",
        "\t\t\tself.model.to(*args, **kwargs)\n",
        "\t \n",
        "\t\tself.relu.to(*args, **kwargs)\n",
        "\t\n",
        "\t\tfor label in self.labelsFC:\n",
        "\t\t\tself.labelsFC[label].to(*args, **kwargs)\n",
        "\t \n",
        "\t\tif self.configuration['use_extra_fc_layer']:\n",
        "\t\t\tself.extra_layer.to(*args, **kwargs)\n",
        "\t\treturn self\n",
        "\t\n",
        "\tdef forward(self, x):\n",
        "\t\tx = self.model(x)\n",
        "\t\tx = self.relu(x)\n",
        "\n",
        "\t\tif self.configuration['use_extra_fc_layer']:\n",
        "\t\t\tx = self.extra_layer(x)\n",
        "\n",
        "\t\tfor label in self.outputs:\n",
        "\t\t\tself.outputs[label] = self.labelsFC[label](x)\n",
        "\t\treturn self.outputs, x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiD1cw1HqUZQ"
      },
      "source": [
        "## Re-Identification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYTRjvD2qUZR"
      },
      "outputs": [],
      "source": [
        "class ResNetIdentification(nn.Module):\n",
        "\tdef __init__(self, class_model_loc=\"pretrained_models/resnet_acc_88.47.h5\"):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.resnet18 = torch.load(class_model_loc)\n",
        "\t\tself.resnet18.relu = nn.Identity() # bypass final layer\n",
        "\t\t# resnet_out_size = 512\n",
        "\n",
        "\tdef to(self, *args, **kwargs):\n",
        "\t\tif args[0] == \"cuda\":\n",
        "\t\t\tself.resnet18.cuda(*args)\n",
        "\t\telse:\n",
        "\t\t\tself.resnet18.to(*args, **kwargs)\n",
        "\t\treturn self\n",
        "\t\n",
        "\tdef forward(self, x):\n",
        "\t\tout, x = self.resnet18(x)\n",
        "\t\treturn x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BtyggZEqUZR"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4rsUkn9qUZR"
      },
      "outputs": [],
      "source": [
        "# create folder to save logs\n",
        "def exp_folder(exp_name):\n",
        "\tif not os.path.isdir(\"runs/\"):\n",
        "\t\tos.mkdir(\"runs/\")\n",
        "\tsuffix = \"\"\n",
        "\ti = 2\n",
        "\twhile os.path.isdir(f\"runs/{exp_name+suffix}\"):\n",
        "\t\tsuffix = str(i)\n",
        "\t\ti+=1\n",
        "\texp_name += suffix\n",
        "\tos.mkdir(f\"runs/{exp_name}\")\n",
        "\treturn exp_name\n",
        "\n",
        "\t\n",
        "def log_data(writer, train_loss, m_ap, epoch):\n",
        "\twriter.add_scalar(\"Distance Loss\", train_loss, epoch)\n",
        "\twriter.add_scalar(\"map mean avg. precision\", m_ap, epoch)\n",
        "\n",
        "def print_data(train_loss, m_ap, epoch):\n",
        "\tprint(\"▚\"*14)\n",
        "\tprint(f\"Epoch: {epoch+1}\")\n",
        "\tprint(f\"distance loss: {train_loss:^10.5f}\")\n",
        "\tprint(f\"m_ap: {m_ap:^10.5f}\")\n",
        "\n",
        "import gc\n",
        "# to clean the gpu memory after testing one model\n",
        "def clean_gpu(model):\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "  model = model.cpu()\n",
        "  model = None\n",
        "  del model\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "def download_to_drive():\n",
        "\tif USING_COLAB:\n",
        "\t  !zip -r /content/filebestbest.zip /content/runs\n",
        "\t  !cp filebestbest.zip /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYFZPCKqqUZT"
      },
      "source": [
        "# mAP and Re-ranking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBarRfJdqUZT"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, Set, List\n",
        "def evaluate_map(predictions: Dict[str, List], ground_truth: Dict[str, Set]):\n",
        "  '''\n",
        "  Computes the mAP (https://jonathan-hui.medium.com/map-mean-average-precision-for-object-detection-45c121a31173) of the predictions with respect to the given ground truth\n",
        "  In person reidentification mAP refers to the mean of the AP over all queries.\n",
        "  The AP for a query is the area under the precision-recall curve obtained from the list of predictions considering the\n",
        "  ground truth elements as positives and the other ones as negatives\n",
        "\n",
        "  :param predictions: dictionary from query filename to list of test image filenames associated with the query ordered\n",
        "                      from the most to the least confident prediction.\n",
        "                      Represents the predictions to be evaluated.\n",
        "  :param ground_truth: dictionary from query filename to set of test image filenames associated with the query\n",
        "                       Represents the ground truth on which to evaluate predictions.\n",
        "\n",
        "  :return:\n",
        "  '''\n",
        "\n",
        "  m_ap = 0.0\n",
        "  for current_ground_truth_query, current_ground_truth_query_set in ground_truth.items():\n",
        "\n",
        "    # No predictions were performed for the current query, AP = 0\n",
        "    if not current_ground_truth_query in predictions:\n",
        "      continue\n",
        "\n",
        "    current_ap = 0.0  # The area under the curve for the current sample\n",
        "    current_predictions_list = predictions[current_ground_truth_query]\n",
        "\n",
        "    # Recall increments of this quantity each time a new correct prediction is encountered in the prediction list\n",
        "    delta_recall = 1.0 / len(current_ground_truth_query_set)\n",
        "\n",
        "    # Goes through the list of predictions\n",
        "    encountered_positives = 0\n",
        "    for idx, current_prediction in enumerate(current_predictions_list):\n",
        "      # Each time a positive is encountered, compute the current precition and the area under the curve\n",
        "      # since the last positive\n",
        "      if current_prediction in current_ground_truth_query_set:\n",
        "        encountered_positives += 1\n",
        "        current_precision = encountered_positives / (idx + 1)\n",
        "        current_ap += current_precision * delta_recall\n",
        "\n",
        "    m_ap += current_ap\n",
        "\n",
        "  # Compute mean over all queries\n",
        "  m_ap /= len(ground_truth)\n",
        "\n",
        "  return m_ap\n",
        "\n",
        "# Code taken from the paper \"Re-ranking Person Re-identification with k-reciprocal Encoding\"\n",
        "# https://github.com/zhunzhong07/person-re-ranking\n",
        "\"\"\"\n",
        "Created on Mon Jun 26 14:46:56 2017\n",
        "@author: luohao\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "CVPR2017 paper:Zhong Z, Zheng L, Cao D, et al. Re-ranking Person Re-identification with k-reciprocal Encoding[J]. 2017.\n",
        "url:http://openaccess.thecvf.com/content_cvpr_2017/papers/Zhong_Re-Ranking_Person_Re-Identification_CVPR_2017_paper.pdf\n",
        "Matlab version: https://github.com/zhunzhong07/person-re-ranking\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "API\n",
        "probFea: all feature vectors of the query set, shape = (image_size, feature_dim)\n",
        "galFea: all feature vectors of the gallery set, shape = (image_size, feature_dim)\n",
        "k1,k2,lambda: parameters, the original paper is (k1=20,k2=6,lambda=0.3)\n",
        "MemorySave: set to 'True' when using MemorySave mode\n",
        "Minibatch: avaliable when 'MemorySave' is 'True'\n",
        "\"\"\"\n",
        "\n",
        "from scipy.spatial.distance import cdist\n",
        "def re_ranking(probFea,galFea,k1=20,k2=6,lambda_value=0.3, MemorySave = False, Minibatch = 2000):\n",
        "\n",
        "    query_num = probFea.shape[0]\n",
        "    all_num = query_num + galFea.shape[0]    \n",
        "    feat = np.append(probFea,galFea,axis = 0)\n",
        "    feat = feat.astype(np.float16)\n",
        "    print('computing original distance')\n",
        "    if MemorySave:\n",
        "        original_dist = np.zeros(shape = [all_num,all_num],dtype = np.float16)\n",
        "        i = 0\n",
        "        while True:\n",
        "            it = i + Minibatch\n",
        "            if it < np.shape(feat)[0]:\n",
        "                original_dist[i:it,] = np.power(cdist(feat[i:it,],feat),2).astype(np.float16)\n",
        "            else:\n",
        "                original_dist[i:,:] = np.power(cdist(feat[i:,],feat),2).astype(np.float16)\n",
        "                break\n",
        "            i = it\n",
        "    else:\n",
        "        original_dist = cdist(feat,feat).astype(np.float16)\n",
        "        original_dist = np.power(original_dist,2).astype(np.float16)\n",
        "    del feat\n",
        "    gallery_num = original_dist.shape[0]\n",
        "    original_dist = np.transpose(original_dist/np.max(original_dist,axis = 0))\n",
        "    V = np.zeros_like(original_dist).astype(np.float16)\n",
        "    initial_rank = np.argsort(original_dist).astype(np.int32)\n",
        "\n",
        "    \n",
        "    print('starting re_ranking')\n",
        "    for i in range(all_num):\n",
        "        # k-reciprocal neighbors\n",
        "        forward_k_neigh_index = initial_rank[i,:k1+1]\n",
        "        backward_k_neigh_index = initial_rank[forward_k_neigh_index,:k1+1]\n",
        "        fi = np.where(backward_k_neigh_index==i)[0]\n",
        "        k_reciprocal_index = forward_k_neigh_index[fi]\n",
        "        k_reciprocal_expansion_index = k_reciprocal_index\n",
        "        for j in range(len(k_reciprocal_index)):\n",
        "            candidate = k_reciprocal_index[j]\n",
        "            candidate_forward_k_neigh_index = initial_rank[candidate,:int(np.around(k1/2))+1]\n",
        "            candidate_backward_k_neigh_index = initial_rank[candidate_forward_k_neigh_index,:int(np.around(k1/2))+1]\n",
        "            fi_candidate = np.where(candidate_backward_k_neigh_index == candidate)[0]\n",
        "            candidate_k_reciprocal_index = candidate_forward_k_neigh_index[fi_candidate]\n",
        "            if len(np.intersect1d(candidate_k_reciprocal_index,k_reciprocal_index))> 2/3*len(candidate_k_reciprocal_index):\n",
        "                k_reciprocal_expansion_index = np.append(k_reciprocal_expansion_index,candidate_k_reciprocal_index)\n",
        "            \n",
        "        k_reciprocal_expansion_index = np.unique(k_reciprocal_expansion_index)\n",
        "        weight = np.exp(-original_dist[i,k_reciprocal_expansion_index])\n",
        "        V[i,k_reciprocal_expansion_index] = weight/np.sum(weight)\n",
        "    original_dist = original_dist[:query_num,]    \n",
        "    if k2 != 1:\n",
        "        V_qe = np.zeros_like(V,dtype=np.float16)\n",
        "        for i in range(all_num):\n",
        "            V_qe[i,:] = np.mean(V[initial_rank[i,:k2],:],axis=0)\n",
        "        V = V_qe\n",
        "        del V_qe\n",
        "    del initial_rank\n",
        "    invIndex = []\n",
        "    for i in range(gallery_num):\n",
        "        invIndex.append(np.where(V[:,i] != 0)[0])\n",
        "    \n",
        "    jaccard_dist = np.zeros_like(original_dist,dtype = np.float16)\n",
        "\n",
        "    \n",
        "    for i in range(query_num):\n",
        "        temp_min = np.zeros(shape=[1,gallery_num],dtype=np.float16)\n",
        "        indNonZero = np.where(V[i,:] != 0)[0]\n",
        "        indImages = []\n",
        "        indImages = [invIndex[ind] for ind in indNonZero]\n",
        "        for j in range(len(indNonZero)):\n",
        "            temp_min[0,indImages[j]] = temp_min[0,indImages[j]]+ np.minimum(V[i,indNonZero[j]],V[indImages[j],indNonZero[j]])\n",
        "        jaccard_dist[i] = 1-temp_min/(2-temp_min)\n",
        "    \n",
        "    final_dist = jaccard_dist*(1-lambda_value) + original_dist*lambda_value\n",
        "    del original_dist\n",
        "    del V\n",
        "    del jaccard_dist\n",
        "    final_dist = final_dist[:query_num,query_num:]\n",
        "    return final_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sODJIOxaqUZU"
      },
      "source": [
        "# Losses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw-xlOEwqUZV"
      },
      "source": [
        "## Custom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0VQ_NgPqUZV"
      },
      "outputs": [],
      "source": [
        "class CustomLoss:\n",
        "\tdef __init__(self) -> None:\n",
        "\t\tpass\n",
        "\n",
        "\t# input shape: (batch_size, n_sample, 512)\n",
        "\tdef __call__(self, features):\n",
        "\t\tminibatch_mean = torch.mean(features, dim=1)\n",
        "\t\tstd_of_means = torch.var(minibatch_mean, dim=0).sum() # this must be maximized\n",
        "\t\tminibatch_std = torch.var(features, dim=1)\n",
        "\t\tminibatch_std = minibatch_std.sum(dim=0).sum() # this must be minimized\n",
        "\t\t# features_std = torch.std(features, dim=2).sum() # this must be maximized\n",
        "\t\treturn minibatch_std - std_of_means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1eQMa7JqUZW"
      },
      "source": [
        "## Centroid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToES0gf2qUZW"
      },
      "outputs": [],
      "source": [
        "class CentroidTripletLoss:\n",
        "\t# - epochPercNearestNegativePhase: \t0 for nearest only, \n",
        "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t1 for random only, \n",
        "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t0.2 for 2phase\n",
        "\t# - incrProbMode: True to use incremental probability mode (bypass first parameter)\n",
        "\tdef __init__(self, epochPercNearestNegativePhase = 0.2, incrProbMode = True) -> None:\n",
        "\t\tself.loss = nn.TripletMarginLoss(reduction=\"none\")\n",
        "\t\tself.epochPercNearestNegativePhase = epochPercNearestNegativePhase\n",
        "\t\tself.incrProbMode = incrProbMode\n",
        "\t\tself.epochPerc = 1\n",
        "\n",
        "\t# input shape: (64, 12, 512)\n",
        "\tdef __call__(self, features):\n",
        "\t\tfeature_per_class = features.shape[1]\n",
        "\t\tloss = torch.Tensor([0.]).to(features.device)\n",
        "\n",
        "\t\tfor i, minibatch in enumerate(features):\n",
        "\t\t\tdist = torch.cdist(features, minibatch, p=1).mean(2).sum(1)\n",
        "\t\t\tmin_args = dist.argsort()[1:].squeeze().cpu().detach().numpy()\n",
        "\t\t\tif self.incrProbMode:\n",
        "\t\t\t\tif np.random.uniform() < 1-self.epochPerc:\n",
        "\t\t\t\t\tneg_idx = np.random.choice(min_args)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tneg_idx = min_args[0]\n",
        "\t\t\telse:\n",
        "\t\t\t\tif self.epochPerc < self.epochPercNearestNegativePhase:\n",
        "\t\t\t\t\tneg_idx = np.random.choice(min_args)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tneg_idx = min_args[0]\n",
        "\t\t\t\n",
        "\t\t\t# compute centroids\n",
        "\t\t\tnegative = features[neg_idx].mean(0).repeat(feature_per_class, 1)\n",
        "\t\t\tpositive = minibatch.mean(0).repeat(feature_per_class, 1)\n",
        "\t\t\t# loss(anchor, positive, negative)\n",
        "\t\t\tloss += self.loss(minibatch, positive, negative).sum()\n",
        "\t\treturn loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpxDAfp_qUZX"
      },
      "source": [
        "## Triplet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdMpZJdgqUZX"
      },
      "outputs": [],
      "source": [
        "class TripletLoss:\n",
        "\t# - nearestIdBased: use id-based strategy\n",
        "\t# - epochPercNearestNegativePhase: \t0 for nearest only, \n",
        "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t1 for random only, \n",
        "\t# \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t0.2 for 2phase\n",
        "\t# - incrProbMode: True to use incremental probability mode (bypass first parameter)\n",
        "\tdef __init__(self, nearestIdBased=False, epochPercNearestNegativePhase = 0.2, incrProbMode = True) -> None:\n",
        "\t\tself.loss = nn.TripletMarginLoss(reduction=\"none\")\n",
        "\t\tself.nearestIdBased = nearestIdBased\n",
        "\t\tself.epochPercNearestNegativePhase = epochPercNearestNegativePhase\n",
        "\t\tself.incrProbMode = incrProbMode\n",
        "\t\tself.epochPerc = 1\n",
        "\n",
        "\t# input shape: (64, 12, 512)\n",
        "\tdef __call__(self, features):\n",
        "\t\tloss = torch.Tensor([0.]).to(features.device)\n",
        "\n",
        "\t\tfor i, minibatch in enumerate(features):\n",
        "\n",
        "\t\t\tif self.nearestIdBased:\n",
        "\t\t\t\tdist = torch.cdist(features, minibatch, p=1).mean(2).sum(1)\n",
        "\t\t\t\tmin_args = dist.argsort()[1:].squeeze().cpu().detach().numpy()\n",
        "\t\t\t\tif self.incrProbMode:\n",
        "\t\t\t\t\tif np.random.uniform() < 1-self.epochPerc:\n",
        "\t\t\t\t\t\tneg_idx = np.random.choice(min_args)\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tneg_idx = min_args[0]\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tif self.epochPerc < self.epochPercNearestNegativePhase:\n",
        "\t\t\t\t\t\tneg_idx = np.random.choice(min_args)\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tneg_idx = min_args[0]\n",
        "\n",
        "\t\t\t\tnegative = features[neg_idx]\n",
        "\n",
        "\t\t\telse:\n",
        "\t\t\t\tnegative_features = torch.cat((features[:i], features[i+1:])).flatten(0,1)\n",
        "\t\t\t\tdist = torch.cdist(negative_features, minibatch, p=1).mean(1)\n",
        "\t\t\t\tmin_dist_idxs = dist.argsort()[:minibatch.shape[0]]\n",
        "\t\t\t\tif self.incrProbMode:\n",
        "\t\t\t\t\tif np.random.uniform() < 1-self.epochPerc:\n",
        "\t\t\t\t\t\tnegative = negative_features[np.random.randint(negative_features.shape[0], size=[minibatch.shape[0]])]\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tnegative = negative_features[min_dist_idxs]\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tif self.epochPerc < self.epochPercNearestNegativePhase:\n",
        "\t\t\t\t\t\tnegative = negative_features[np.random.randint(negative_features.shape[0], size=[minibatch.shape[0]])]\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tnegative = negative_features[min_dist_idxs]\n",
        "\t\t\t\n",
        "\t\t\tpositive = torch.flip(minibatch, [0])\n",
        "\t\t\t# loss(anchor, positive, negative)\n",
        "\t\t\tloss += self.loss(minibatch, positive, negative).sum()\n",
        "\t\treturn loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti7TiaBbqUZY"
      },
      "source": [
        "## Multi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtX2P0G-qUZY"
      },
      "outputs": [],
      "source": [
        "class MultiLoss:\n",
        "\tdef __init__(self) -> None:\n",
        "\t\tself.tripletLoss = TripletLoss(False, 0, True)\n",
        "\t\tself.centroidLoss = CentroidTripletLoss(False, True)\n",
        "\t\tself.customLoss = CustomLoss()\n",
        "\t\tself.epochPerc = 1\n",
        "\t\tself.w = [10, 5, 1] # weights for each loss (triplet, centorid, custom)\n",
        "\n",
        "\tdef __call__(self, features):\n",
        "\t\tself.tripletLoss.epochPerc = self.epochPerc\n",
        "\t\tself.centroidLoss.epochPerc = self.epochPerc\n",
        "\t\tloss1 = self.tripletLoss(features)\n",
        "\t\tloss2 = self.centroidLoss(features)\n",
        "\t\tloss3 = self.customLoss(features)\n",
        "\t\treturn loss1 * self.w[0] + loss2 * self.w[1] + loss3 * self.w[2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9bf6CbZqUZZ"
      },
      "source": [
        "# Train and Test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LdH98qYKqUZZ"
      },
      "outputs": [],
      "source": [
        "def train_reid(net, data_loader, optimizer, cost_function, device=\"cpu\"):\n",
        "\ttot_samples = cumulative_loss = 0.\n",
        "\n",
        "\tnet.train()\n",
        "\twith torch.set_grad_enabled(True):\n",
        "\t\tfor batch_idx, inputs in enumerate(data_loader):\n",
        "\n",
        "\t\t\t# reshape the batch from (batchsize, n_select, 3, 128, 64) to (batchsize*n_select, 3, 128 , 64)\n",
        "\t\t\t# in order to get the shape compatible for the model\n",
        "\t\t\tinputs = inputs.to(device) # (64, 12, 3, 128, 64)\n",
        "\t\t\ts = inputs.shape\n",
        "\t\t\tinputs = inputs.reshape((s[0] * s[1], s[2], s[3], s[4])) # (64*12, 3, 128 , 64)\n",
        "\t\t\ttot_samples += s[0] * s[1]\n",
        "\n",
        "\t\t\toutputs = net(inputs) # (64*12, 512)\n",
        "\n",
        "\t\t\t# reshape to obtain groups of features belonging to the same id: (batchsize, n_select, feature_size)\n",
        "\t\t\toutputs = outputs.reshape((s[0], s[1], outputs.shape[1])) # (64, 12, 512)\n",
        "\n",
        "\t\t\tloss = cost_function(outputs)\n",
        "\n",
        "\t\t\tloss.backward()\n",
        "\t\t\toptimizer.step()\n",
        "\t\t\toptimizer.zero_grad()\n",
        "\t\t\t\n",
        "\t\t\tcumulative_loss += loss.item()\n",
        "\n",
        "\treturn cumulative_loss/tot_samples\n",
        "\n",
        "def test_reid(net, data_loader, device=\"cpu\", useReranking=False, select_size=0):\n",
        "\tground_truth = data_loader.dataset.ground_truth\n",
        "\n",
        "\t# first compute all the features\n",
        "\tnet.eval()\n",
        "\twith torch.no_grad():\n",
        "\t\tall_features = torch.Tensor()\n",
        "\t\tfor i, batch in enumerate(data_loader):\n",
        "\t\t\tfeatures = net(batch.to(device))\n",
        "\t\t\tall_features = torch.cat((all_features, features.to(\"cpu\")))\n",
        "\t\n",
        "\tif useReranking:\n",
        "\t\tdist_matrix = re_ranking(all_features, all_features)\n",
        "\n",
        "\t# then compute distance and the prediction dict {id: [list ids]}\n",
        "\tpredictions = {}\n",
        "\tfor index in ground_truth.keys():\n",
        "\t\t\n",
        "\t\tif useReranking:\n",
        "\t\t\tdist = dist_matrix[index]\n",
        "\t\telse:\n",
        "\t\t\tdist = torch.cdist(all_features, all_features[index][None, :], p=1).squeeze()\n",
        "\n",
        "\t\tif select_size > 0:\n",
        "\t\t\tmin_args = dist.argsort()[1:select_size]\n",
        "\t\telse:\n",
        "\t\t\tmin_args = dist.argsort()[1:]\n",
        "\n",
        "\t\tpredictions[index] = min_args.tolist()\n",
        "\n",
        "\tm_ap = evaluate_map(predictions, ground_truth)\n",
        "\n",
        "\treturn m_ap * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YMMS4hbzqUZZ"
      },
      "outputs": [],
      "source": [
        "def main(net, train_batch_size, valid_batch_size, device, epochs, optimizer, cost_function, data_dir, train_sample_ratio, min_group_length, n_select, exp_name=\"reid\"):\n",
        "\t# Creates a logger for the experiment\n",
        "\tmax_map = epochs_without_improvements = 0\n",
        "\texp_name = exp_folder(exp_name)\n",
        "\twriter = SummaryWriter(log_dir=f\"runs/{exp_name}\", comment=f\"experiment {exp_name}\")\n",
        "\n",
        "\ttrain_loader, valid_loader = get_data(train_batch_size, valid_batch_size, data_dir, train_sample_ratio, min_group_length, n_select)\n",
        "\n",
        "\tfor e in range(epochs):\n",
        "\t\t\n",
        "\t\t# set to the loss the epoch percentage: curr_epoch / max_epochs\n",
        "\t\tif type(cost_function).__name__ == \"TripletLoss\" or type(cost_function).__name__ == \"CentroidTripletLoss\":\n",
        "\t\t\tcost_function.epochPerc = e / epochs\n",
        "\n",
        "\t\ttrain_loss = train_reid(net, train_loader, optimizer, cost_function, device)\n",
        "\t\tm_ap = test_reid(net, valid_loader, device)\n",
        "\n",
        "\t\tlog_data(writer, train_loss, m_ap, e)\n",
        "\n",
        "\t\tprint_data(train_loss, m_ap, e)\n",
        "\n",
        "\t\t# save the weights when accuracy increases\n",
        "\t\tmax_map = max(m_ap, max_map)\n",
        "\t\tif max_map == m_ap:\n",
        "\t\t\tprint(\"Best accuracy: {0}\".format(max_map))\n",
        "\t\t\tepochs_without_improvements = 0\n",
        "\t\t\tif max_map > 68:\n",
        "\t\t\t\tmodel_name = 'reid_{0}.h5'.format(round(max_map, 2))\n",
        "\t\t\t\ttorch.save(net, model_name)\n",
        "\t\t\t\tif USING_COLAB:\n",
        "\t\t\t\t\tos.system(\"cp {0} /content/drive/MyDrive/\".format(model_name))\n",
        "\t\t\telse:\n",
        "\t\t\t\tepochs_without_improvements += 1\n",
        "\t\t\t\tprint(\"Epochs without improvements: {0}\".format(epochs_without_improvements))\n",
        "\n",
        "\t# Compute Re-ranking at the end\n",
        "\tm_ap = test_reid(net, valid_loader, device, True)\n",
        "\tprint(\"\\nFinal test with reranking...\\n\")\n",
        "\tprint_data(train_loss, m_ap, e+1)\n",
        "\t\n",
        "\twriter.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M22_clQbqUZa"
      },
      "source": [
        "# Start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3mmrBMPqUZb"
      },
      "outputs": [],
      "source": [
        "epochs = 50\n",
        "train_batch_size = 128\n",
        "test_batch_size = 512\n",
        "min_group_length = 12\n",
        "n_select = 12 # even number <= min_group_length\n",
        "train_sample_ratio = 0.8\n",
        "device = \"cuda\"\n",
        "data_dir = \"train\"\n",
        "lr = 1.5e-4\n",
        "weight_decay = 1e-3\n",
        "cost_function = TripletLoss() # default incr. prob. mode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0rzZPnPqUZb"
      },
      "source": [
        "## Single Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgyBnSepqUZc"
      },
      "outputs": [],
      "source": [
        "net = ResNetIdentification(\"pretrained_models/resnet_18_acc_70_30_seed_26_88.63.h5\")\n",
        "net = net.to(device)\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "main(net, train_batch_size, test_batch_size, device, epochs, optimizer, cost_function, data_dir, train_sample_ratio, min_group_length, n_select, \"reid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJrQbRg_qUZc"
      },
      "source": [
        "## Multi Training for experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Jo_jMyVhbAD"
      },
      "outputs": [],
      "source": [
        "configurations = {\n",
        "\t'reid_triplet_incr_prob' : {\n",
        "\t\t'model' : \"pretrained_models/resnet_18_acc_70_30_seed_26_88.63.h5\",\n",
        "\t\t'loss' : TripletLoss(False, 0, True)\n",
        "\t\t},\n",
        "\t'reid_triplet_nearest_only' : {\n",
        "\t\t'model' : \"pretrained_models/resnet_18_acc_70_30_seed_26_88.63.h5\",\n",
        "\t\t'loss' : TripletLoss(False, 0, False)\n",
        "\t\t},\n",
        "\t'reid_centroid_incr_prob' : {\n",
        "\t\t'model' : \"pretrained_models/resnet_18_acc_70_30_seed_26_88.63.h5\",\n",
        "\t\t'loss' : CentroidTripletLoss(0, True)\n",
        "\t\t},\n",
        "\t'reid_custom_loss' : {\n",
        "\t\t'model' : \"pretrained_models/resnet_18_acc_70_30_seed_26_88.63.h5\",\n",
        "\t\t'loss' : CustomLoss()\n",
        "\t\t}\n",
        "}\n",
        "\n",
        "# Run multiple experiment\n",
        "def multi_experiments(configurations, num_repeated_training = 1):\n",
        "\tfor i in range(num_repeated_training):\n",
        "\t\tfor exp_name, configuration in configurations.items():\n",
        "\n",
        "\t\t\t# create the network\n",
        "\t\t\tnet = ResNetIdentification(configuration[\"model\"])\n",
        "\t\t\tnet = net.to(device)\n",
        "\t\t\toptimizer = torch.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\t\t\tcost_function = configuration[\"loss\"]\n",
        "\n",
        "\t\t\tprint('#######################################')\n",
        "\t\t\tprint(exp_name)\n",
        "\t\t\tprint('#######################################')\n",
        "\n",
        "\t\t\t# train the network\n",
        "\t\t\tmain(net, train_batch_size, test_batch_size, device, epochs, optimizer, cost_function, data_dir, train_sample_ratio, min_group_length, n_select, exp_name)\n",
        "\t\t\t\n",
        "\t\t\tdownload_to_drive()\n",
        "\n",
        "\t\t\tclean_gpu(net)\n",
        "\n",
        "# multi_experiments(configurations, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbGiwEbkhbAD"
      },
      "outputs": [],
      "source": [
        "# %load_ext tensorboard\n",
        "# !rmdir /s /q \"%appdata%/../Local/Temp/.tensorboard-info\" # Windows only\n",
        "# %tensorboard --logdir runs/ --host localhost --port 8888\n",
        "# if you use vscode go to http://localhost:8888/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFHE6stNhbAE"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK1zXLn6hbAE"
      },
      "source": [
        "## Generate distance matrix from query and test features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_q1AQBe7hbAF"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "\tdef __init__(self, directory) -> None:\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.dir = directory\n",
        "\t\tself.transform = T.Compose([\n",
        "\t\t\tT.ToTensor(),\n",
        "\t\t\tT.Normalize(mean=[0.], std=[1.])\n",
        "\t\t])\n",
        "\t\tself.file_list = sorted(os.listdir(directory))\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\timg = Image.open(os.path.join(self.dir, self.file_list[index]))\n",
        "\t\tif self.transform:\n",
        "\t\t\timg = self.transform(img)\n",
        "\t\treturn img\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.file_list)\n",
        "\n",
        "def generate_dist_matrix(net, query_dataset, test_dataset, device = \"cuda\", batch_size = 512):\n",
        "\tnet.eval()\n",
        "\tnet.to(device)\n",
        "\ttest_loader = torch.utils.data.DataLoader(test_dataset, batch_size, shuffle=False)\n",
        "\tquery_loader = torch.utils.data.DataLoader(query_dataset, batch_size, shuffle=False)\n",
        "\n",
        "\twith torch.no_grad():\n",
        "\t\ttest_features = torch.Tensor()\n",
        "\t\tfor i, batch in enumerate(test_loader):\n",
        "\t\t\tfeatures = net(batch.to(device))\n",
        "\t\t\ttest_features = torch.cat((test_features, features.to(\"cpu\")))\n",
        "\n",
        "\t\t\tprint(f\"\\rComputing test features: {i+1}/{len(test_loader)}\", end=\"\")\n",
        "\t\tprint()\n",
        "\n",
        "\t\tquery_features = torch.Tensor()\n",
        "\t\tfor i, batch in enumerate(query_loader):\n",
        "\t\t\tfeatures = net(batch.to(device))\n",
        "\t\t\tquery_features = torch.cat((query_features, features.to(\"cpu\")))\n",
        "\n",
        "\t\t\tprint(f\"\\rComputing query features: {i+1}/{len(query_loader)}\", end=\"\")\n",
        "\n",
        "\tprint(\"\\nComputing reranking pass...\")\n",
        "\tdist_matrix = re_ranking(query_features, test_features)\n",
        "\treturn dist_matrix\n",
        "\n",
        "\n",
        "# net = torch.load(\"pretrained_models/reid_map_68.63.h5\")\n",
        "query_dataset = ImageDataset(\"queries\")\n",
        "test_dataset = ImageDataset(\"test\")\n",
        "dist_matrix = generate_dist_matrix(net, query_dataset, test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDEMLJuvhbAF"
      },
      "source": [
        "## Generate prediction file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhiR8mJJhbAF"
      },
      "outputs": [],
      "source": [
        "def write_prediction_file(dist_matrix, query_dataset, test_dataset):\n",
        "\tif not os.path.isdir(\"predictions\"):\n",
        "\t\tos.mkdir(\"predictions\")\n",
        "\twith open(\"predictions/reid_test2.txt\", \"w+\") as reid_test_file:\n",
        "\t\tselect_size = 100\n",
        "\t\ttest_data_file_list = np.array(test_dataset.file_list)\n",
        "\n",
        "\t\tfor index in range(len(query_dataset)):\n",
        "\t\t\tdist = dist_matrix[index]\n",
        "\t\t\tmin_args = dist.argsort()[:select_size]\n",
        "\t\t\tbest_file_list = test_data_file_list[min_args].tolist()\n",
        "\t\t\ts = ', '.join(best_file_list)\n",
        "\t\t\tentry_line = f'{query_dataset.file_list[index]}: {s}\\n'\n",
        "\t\t\treid_test_file.write(entry_line)\n",
        "\n",
        "write_prediction_file(dist_matrix, query_dataset, test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F3kOm5Q_hbAF"
      },
      "outputs": [],
      "source": [
        "def show_prediction(query_img_id, dist_matrix, query_data, test_data, n_select = 50, treshold = None):\n",
        "\timg = query_data[query_img_id]\n",
        "\tplt.imshow(img.permute(1,2,0))\n",
        "\tplt.show()\n",
        "\n",
        "\tdist = dist_matrix[query_img_id]\n",
        "\tmin_args = dist.argsort().squeeze()\n",
        "\n",
        "\ttreshold_enc = False\n",
        "\tfig, axs = plt.subplots(n_select//10, 10, figsize=(16,17))\n",
        "\tfor i, ax_r in enumerate(axs):\n",
        "\t\tif treshold_enc: break\n",
        "\t\tfor j, ax in enumerate(ax_r):\n",
        "\t\t\tidx = (i*10)+j\n",
        "\t\t\tbest_img = test_data[min_args[idx]]\n",
        "\t\t\tax.imshow(best_img.permute(1,2,0))\n",
        "\t\t\tax.set_title(dist[min_args[idx]])\n",
        "\t\t\tif treshold and dist[min_args[idx]] > treshold:\n",
        "\t\t\t\ttreshold_enc = True\n",
        "\t\t\t\tbreak\n",
        "\n",
        "show_prediction(126, dist_matrix, query_dataset, test_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "model_reidentification.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "f24249645a37ed3cde8ea83dc21f5c7b99f355afa532b6d6c25df59297445f37"
    },
    "kernelspec": {
      "display_name": "Python 3.7.12 64-bit ('pytorch': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}